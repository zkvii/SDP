{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-21 01:22:47,511 - mindformers[auto_class.py:661] - INFO - Config in the yaml file ./checkpoint_download/gpt2/gpt2.yaml are used for tokenizer building.\n",
      "2023-09-21 01:22:47,530 - mindformers[auto_class.py:668] - INFO - Load the tokenizer name GPT2Tokenizer from the ./checkpoint_download/gpt2/gpt2.yaml\n",
      "2023-09-21 01:22:47,547 - mindformers[base_tokenizer.py:1979] - INFO - config in the yaml file ./checkpoint_download/gpt2/gpt2.yaml are used for tokenizer building.\n",
      "2023-09-21 01:22:47,565 - mindformers[base_tokenizer.py:1988] - WARNING - Can't find the tokenizer_config.json in the file_dict. The content of file_dict is : {}\n",
      "2023-09-21 01:22:47,566 - mindformers[base_tokenizer.py:1994] - INFO - build tokenizer class name is: GPT2Tokenizer using args {'unk_token': '<|endoftext|>', 'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'vocab_file': './checkpoint_download/gpt2/vocab.json', 'merges_file': './checkpoint_download/gpt2/merges.txt'}.\n",
      "2023-09-21 01:22:47,614 - mindformers[auto_class.py:767] - INFO - GPT2Tokenizer Tokenizer built successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1534200:139633736206144,MainProcess):2023-09-21-01:22:47.633.330 [mindspore/ops/primitive.py:228] The in_strategy of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. \n",
      "If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL)\n",
      "[WARNING] ME(1534200:139633736206144,MainProcess):2023-09-21-01:22:47.703.031 [mindspore/common/parameter.py:778] This interface may be deleted in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-21 01:22:48,089 - mindformers[base_model.py:117] - INFO - start to read the ckpt file: 497772028\n",
      "2023-09-21 01:22:48,980 - mindformers[base_model.py:121] - INFO - weights in ./checkpoint_download/gpt2/gpt2.ckpt are loaded\n",
      "2023-09-21 01:22:48,984 - mindformers[auto_class.py:418] - INFO - model built successfully!\n"
     ]
    }
   ],
   "source": [
    "from mindformers import AutoModel, AutoTokenizer, TextStreamer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import load_checkpoint,load_param_into_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load c1 model\n",
    "# params_dict=load_checkpoint('./output/checkpoint/rank_0/gpt_rank_0_1-960_1.ckpt')\n",
    "#load c2 model\n",
    "# params_dict=load_checkpoint('./output/checkpoint/rank_0/gpt_rank_0_2-840_1.ckpt')\n",
    "#load target model\n",
    "params_dict=load_checkpoint('./output/checkpoint/rank_0/gpt_rank_0-1500_1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=load_param_into_net(model,params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    \"微信\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_text, max_length=128, padding=\"max_length\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-21 01:31:05,563 - mindformers[text_generator.py:435] - INFO - total time: 11.115434408187866 s; generated tokens: 124 tokens; generate speed: 11.155659369341333 tokens/s\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=128, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['微信 号 a T e P a r P a\\n陶 刚 身 份 证 号 码 8 8 3 8 8 1 1 9 5 1 1 1 2 2 2 手 机 号 码 1 3 9 2 2 2 2 3 0 3 信 用 卡 号 4 8 8 3 0 2 3 0 0 0 0 0 0 0 2 银 行 卡 号 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_data import train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length =1025\n",
    "merge_train_data=[ '<q>'+row['question']+\"<a>\"+row['answer'] for row in train_data]\n",
    "merge_test_data=[ '<q>'+row['question']+\"<a>\"+row['answer'] for row in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequences, max_length):\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) < max_length:\n",
    "            sequence = sequence + tok.pad_token * (max_length - len(sequence))\n",
    "        else:\n",
    "            sequence = sequence[:max_length]\n",
    "        padded_sequences.append(sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_train=pad_sequence(merge_train_data, max_length)\n",
    "pad_test=pad_sequence(merge_test_data, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/nsc4.train.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(merge_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/nsc4.test.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(merge_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
